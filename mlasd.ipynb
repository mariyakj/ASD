{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariyakj/ASD/blob/main/mlasd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7k3htUYl_Ws",
        "outputId": "11258b5b-5b62-44a0-cf3e-8c4f446f24df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgl-G3NPwpSP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vTywMsRmpNB"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "# Import libraries necessary for this project\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "\n",
        "# Pretty display for notebooks\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pLO_gPKgm43e",
        "outputId": "f97fb666-f73f-467c-94c4-af8433d90831"
      },
      "outputs": [
        {
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b1a32ae89696>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#mount google drive to colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "#mount google drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QvF-uQUUnMlg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the file path\n",
        "file = '/content/gdrive/MyDrive/Toddler Autism dataset July 2018 new.csv - Toddler Autism dataset July 2018.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "asd_data = pd.read_csv(file)\n",
        "#print some random data\n",
        "print(asd_data.loc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XL4ZjQwcnQ1S"
      },
      "outputs": [],
      "source": [
        "asd_data.loc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NQuPCyWxn-lo"
      },
      "outputs": [],
      "source": [
        "asd_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WGsB-h-foP-s"
      },
      "outputs": [],
      "source": [
        "# Analysing the data\n",
        "n_records = len(asd_data.index)\n",
        "\n",
        "# TODO: Number of records where individual's with ASD\n",
        "n_asd_yes = len(asd_data[asd_data['Class/ASD Traits '] == 1])\n",
        "\n",
        "# TODO: Number of records where individual's with no ASD\n",
        "n_asd_no = len(asd_data[asd_data['Class/ASD Traits '] == 0])\n",
        "\n",
        "# TODO: Percentage of individuals whose are with ASD\n",
        "yes_percent = float(n_asd_yes) / n_records *100\n",
        "\n",
        "# Print the results\n",
        "print (\"Total number of records: {}\".format(n_records))\n",
        "print (\"Individuals diagonised with ASD: {}\".format(n_asd_yes))\n",
        "print (\"Individuals not diagonised with ASD: {}\".format(n_asd_no))\n",
        "print (\"Percentage of individuals diagonised with ASD: {:.2f}%\".format(yes_percent))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gCnMFbFdosKc"
      },
      "outputs": [],
      "source": [
        "asd_data = pd.read_csv('/content/gdrive/MyDrive/Toddler Autism dataset July 2018 new.csv - Toddler Autism dataset July 2018.csv', na_values=['?'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P1FA7G8vyD4W"
      },
      "outputs": [],
      "source": [
        "asd_data.loc[(asd_data['Age_Mons'].isnull()) |(asd_data['Qchat-10-Score'].isnull()) |(asd_data['Sex'].isnull())\n",
        "|(asd_data['Ethnicity'].isnull())|(asd_data['Jaundice'].isnull()) |(asd_data['Family_mem_with_ASD'].isnull())\n",
        "            |(asd_data['Who completed the test'].isnull())|(asd_data['contry_of_res'].isnull())|(asd_data['used_app_before'].isnull())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ps3Z169wzQVV"
      },
      "outputs": [],
      "source": [
        "#inplace=True argument means that the changes are applied directly to the original DataFrame asd_data, without creating a new DataFrame.\n",
        "#clean dataset\n",
        "asd_data.dropna(inplace=True)\n",
        "asd_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B13C9jVYzbD0"
      },
      "outputs": [],
      "source": [
        "# Reminder of the features:\n",
        "print(asd_data.dtypes)\n",
        "\n",
        "\n",
        "# Total number of records in clean dataset\n",
        "n_records = len(asd_data.index)\n",
        "\n",
        "# TODO: Number of records where individual's with ASD in the clean dataset\n",
        "n_asd_yes = len(asd_data[asd_data['Class/ASD Traits '] == 1])\n",
        "\n",
        "# TODO: Number of records where individual's with no ASD in the clean dataset\n",
        "n_asd_no = len(asd_data[asd_data['Class/ASD Traits '] == 0])\n",
        "\n",
        "# Print the results\n",
        "print (\"Total number of records: {}\".format(n_records))\n",
        "print (\"Individuals diagonised with ASD: {}\".format(n_asd_yes))\n",
        "print (\"Individuals not diagonised with ASD: {}\".format(n_asd_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CwuvfQci1M-L"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Assuming 'asd_data' is loaded or defined elsewhere\n",
        "# Split the data into features and target label\n",
        "asd_raw = asd_data['Class/ASD Traits ']\n",
        "\n",
        "# Include all features in the dataset\n",
        "features_raw = asd_data[['Case_No', 'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'Age_Mons', 'Qchat-10-Score', 'Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD', 'Who completed the test', 'contry_of_res', 'used_app_before']]\n",
        "\n",
        "# Scale the numerical feature 'Age_Mons' using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numerical = ['Age_Mons']\n",
        "features_minmax_transform = pd.DataFrame(data=features_raw)\n",
        "features_minmax_transform[numerical] = scaler.fit_transform(features_raw[numerical])\n",
        "\n",
        "# One-hot encode the features\n",
        "features_final = pd.get_dummies(features_minmax_transform)\n",
        "display(features_final.head(5))\n",
        "\n",
        "# Encode the target classes to numerical values\n",
        "asd_classes = asd_raw\n",
        "\n",
        "# Print the number of features after one-hot encoding\n",
        "encoded = list(features_final.columns)\n",
        "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
        "print(encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_nZ5mhS-9bKe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming asd_classes is your data containing class/ASD values\n",
        "\n",
        "# 8 bins\n",
        "plt.hist(asd_classes, bins=10)\n",
        "\n",
        "# x-axis limit from 0 to 1\n",
        "plt.xlim(0, 1)\n",
        "plt.title('Histogram of Class/ASD')\n",
        "plt.xlabel('Class/ASD from processed data')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nf74XbaK9HuN"
      },
      "outputs": [],
      "source": [
        "#Shuffle and Split Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_final, asd_classes, train_size=0.80, random_state=1)\n",
        "\n",
        "\n",
        "# Show the results of the split\n",
        "print( \"Training set has {} samples.\".format(X_train.shape[0]))\n",
        "print (\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
        "#asd_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0vi3pZNptPMG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Create a pipeline with model\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', DecisionTreeClassifier())  # You can replace DecisionTreeClassifier with any other classifier\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "model_path = '/content/gdrive/MyDrive/ml_models/decision_tree_model.pkl'\n",
        "with open(model_path, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on test set\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_test * 100))\n",
        "\n",
        "# Generate confusion matrix for test set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "print(\"Confusion Matrix on test set:\")\n",
        "print(conf_matrix_test)\n",
        "\n",
        "def get_user_input():\n",
        "    features = []\n",
        "    print(\"Enter values for the 20 features:\")\n",
        "\n",
        "    # Integer features\n",
        "    for i in range(13):\n",
        "        value = int(input(f\"Feature {i+1}: \"))\n",
        "        features.append(value)\n",
        "\n",
        "    # Categorical features\n",
        "    categorical_features = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
        "                            'Who completed the test', 'contry_of_res', 'used_app_before']\n",
        "    for feature in categorical_features:\n",
        "        print(f\"Enter value for {feature}: \")\n",
        "        value = input()\n",
        "        features.append(value)\n",
        "\n",
        "    # Create DataFrame with correct column names\n",
        "    columns = ['Case_No'] + ['A'+str(i) for i in range(1, 11)] + ['Age_Mons', 'Qchat-10-Score']\n",
        "\n",
        "    # Include categorical features in 'columns'\n",
        "    columns += categorical_features\n",
        "\n",
        "\n",
        "    # Ensure that the number of columns in 'columns' matches the number of features\n",
        "    assert len(columns) == len(features), \"Number of columns does not match number of features\"\n",
        "\n",
        "    # Create DataFrame using the provided features and columns\n",
        "    user_features = pd.DataFrame([features], columns=columns)\n",
        "\n",
        "    # Convert categorical features to one-hot encoding\n",
        "    user_features_encoded = pd.get_dummies(user_features, columns=categorical_features)\n",
        "\n",
        "    # Realign with features_final columns\n",
        "    user_features_aligned = user_features_encoded.reindex(columns=features_final.columns, fill_value=0)\n",
        "\n",
        "    return user_features_aligned\n",
        "\n",
        "\n",
        "\n",
        "# Get user input for the 20 features\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Perform prediction\n",
        "prediction = pipeline.predict(user_features)\n",
        "\n",
        "# Print the prediction\n",
        "if prediction[0] == 0:\n",
        "    print(\"Prediction: Non-autistic\")\n",
        "else:\n",
        "    print(\"Prediction: Autistic\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "48U0PaMSx97Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "# Define function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "\n",
        "# Reverse the confusion matrix\n",
        "conf_matrix_test_reversed = conf_matrix_test[::-1, ::-1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_matrix_test_reversed, title='Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dzu8aFWgEU_f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Create a pipeline with model\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier())  # You can replace DecisionTreeClassifier with any other classifier\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "model_path = '/content/gdrive/MyDrive/ml_models/random_forest_model.pkl'\n",
        "with open(model_path, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on test set\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_test * 100))\n",
        "\n",
        "# Generate confusion matrix for test set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "def get_user_input():\n",
        "    features = []\n",
        "    print(\"Enter values for the 20 features:\")\n",
        "\n",
        "    # Integer features\n",
        "    for i in range(13):\n",
        "        value = int(input(f\"Feature {i+1}: \"))\n",
        "        features.append(value)\n",
        "\n",
        "    # Categorical features\n",
        "    categorical_features = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
        "                            'Who completed the test', 'contry_of_res', 'used_app_before']\n",
        "    for feature in categorical_features:\n",
        "        print(f\"Enter value for {feature}: \")\n",
        "        value = input()\n",
        "        features.append(value)\n",
        "\n",
        "    # Create DataFrame with correct column names\n",
        "    columns = ['Case_No'] + ['A'+str(i) for i in range(1, 11)] + ['Age_Mons', 'Qchat-10-Score']\n",
        "\n",
        "    # Include categorical features in 'columns'\n",
        "    columns += categorical_features\n",
        "\n",
        "\n",
        "    # Ensure that the number of columns in 'columns' matches the number of features\n",
        "    assert len(columns) == len(features), \"Number of columns does not match number of features\"\n",
        "\n",
        "    # Create DataFrame using the provided features and columns\n",
        "    user_features = pd.DataFrame([features], columns=columns)\n",
        "\n",
        "    # Convert categorical features to one-hot encoding\n",
        "    user_features_encoded = pd.get_dummies(user_features, columns=categorical_features)\n",
        "\n",
        "    # Realign with features_final columns\n",
        "    user_features_aligned = user_features_encoded.reindex(columns=features_final.columns, fill_value=0)\n",
        "\n",
        "    return user_features_aligned\n",
        "\n",
        "\n",
        "\n",
        "# Get user input for the 20 features\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Perform prediction\n",
        "prediction = pipeline.predict(user_features)\n",
        "\n",
        "# Print the prediction\n",
        "if prediction[0] == 0:\n",
        "    print(\"Prediction: Non-autistic\")\n",
        "else:\n",
        "    print(\"Prediction: Autistic\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Lw0-llD54Iwz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "# Define function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "\n",
        "# Reverse the confusion matrix\n",
        "conf_matrix_test_reversed = conf_matrix_test[::-1, ::-1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_matrix_test_reversed, title='Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DvNWep1IEgL-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# Create a pipeline with model\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', SVC())  # You can replace DecisionTreeClassifier with any other classifier\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "model_path = '/content/gdrive/MyDrive/ml_models/svm_model.pkl'\n",
        "with open(model_path, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on test set\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_test * 100))\n",
        "\n",
        "# Generate confusion matrix for test set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "def get_user_input():\n",
        "    features = []\n",
        "    print(\"Enter values for the 20 features:\")\n",
        "\n",
        "    # Integer features\n",
        "    for i in range(13):\n",
        "        value = int(input(f\"Feature {i+1}: \"))\n",
        "        features.append(value)\n",
        "\n",
        "    # Categorical features\n",
        "    categorical_features = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
        "                            'Who completed the test', 'contry_of_res', 'used_app_before']\n",
        "    for feature in categorical_features:\n",
        "        print(f\"Enter value for {feature}: \")\n",
        "        value = input()\n",
        "        features.append(value)\n",
        "\n",
        "    # Create DataFrame with correct column names\n",
        "    columns = ['Case_No'] + ['A'+str(i) for i in range(1, 11)] + ['Age_Mons', 'Qchat-10-Score']\n",
        "\n",
        "    # Include categorical features in 'columns'\n",
        "    columns += categorical_features\n",
        "\n",
        "\n",
        "    # Ensure that the number of columns in 'columns' matches the number of features\n",
        "    assert len(columns) == len(features), \"Number of columns does not match number of features\"\n",
        "\n",
        "    # Create DataFrame using the provided features and columns\n",
        "    user_features = pd.DataFrame([features], columns=columns)\n",
        "\n",
        "    # Convert categorical features to one-hot encoding\n",
        "    user_features_encoded = pd.get_dummies(user_features, columns=categorical_features)\n",
        "\n",
        "    # Realign with features_final columns\n",
        "    user_features_aligned = user_features_encoded.reindex(columns=features_final.columns, fill_value=0)\n",
        "\n",
        "    return user_features_aligned\n",
        "\n",
        "\n",
        "\n",
        "# Get user input for the 20 features\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Perform prediction\n",
        "prediction = pipeline.predict(user_features)\n",
        "\n",
        "# Print the prediction\n",
        "if prediction[0] == 0:\n",
        "    print(\"Prediction: Non-autistic\")\n",
        "else:\n",
        "    print(\"Prediction: Autistic\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_TQOxJio5kUw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "# Define function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "\n",
        "# Reverse the confusion matrix\n",
        "conf_matrix_test_reversed = conf_matrix_test[::-1, ::-1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_matrix_test_reversed, title='Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "riCrQIULEi8C"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "('classifier', GaussianNB())\n",
        "model_path = '/content/gdrive/MyDrive/ml_models/naive_bayes_model.pkl'\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import pickle\n",
        "\n",
        "# Shuffle and Split Data\n",
        "np.random.seed(1234)\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_final, asd_classes, train_size=0.80, random_state=1)\n",
        "\n",
        "# Create a pipeline with model\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', GaussianNB())  # You can replace DecisionTreeClassifier with any other classifier\n",
        "])\n",
        "\n",
        "# Fit the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "model_path = '/content/gdrive/MyDrive/ml_models/naive_bayes_model.pkl'\n",
        "with open(model_path, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n",
        "\n",
        "# Predict the labels for the test set\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate accuracy on test set\n",
        "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "print(\"Accuracy on test set: {:.2f}%\".format(accuracy_test * 100))\n",
        "\n",
        "# Generate confusion matrix for test set\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "def get_user_input():\n",
        "    features = []\n",
        "    print(\"Enter values for the 20 features:\")\n",
        "\n",
        "    # Integer features\n",
        "    for i in range(13):\n",
        "        value = int(input(f\"Feature {i+1}: \"))\n",
        "        features.append(value)\n",
        "\n",
        "    # Categorical features\n",
        "    categorical_features = ['Sex', 'Ethnicity', 'Jaundice', 'Family_mem_with_ASD',\n",
        "                            'Who completed the test', 'contry_of_res', 'used_app_before']\n",
        "    for feature in categorical_features:\n",
        "        print(f\"Enter value for {feature}: \")\n",
        "        value = input()\n",
        "        features.append(value)\n",
        "\n",
        "    # Create DataFrame with correct column names\n",
        "    columns = ['Case_No'] + ['A'+str(i) for i in range(1, 11)] + ['Age_Mons', 'Qchat-10-Score']\n",
        "\n",
        "    # Include categorical features in 'columns'\n",
        "    columns += categorical_features\n",
        "\n",
        "\n",
        "    # Ensure that the number of columns in 'columns' matches the number of features\n",
        "    assert len(columns) == len(features), \"Number of columns does not match number of features\"\n",
        "\n",
        "    # Create DataFrame using the provided features and columns\n",
        "    user_features = pd.DataFrame([features], columns=columns)\n",
        "\n",
        "    # Convert categorical features to one-hot encoding\n",
        "    user_features_encoded = pd.get_dummies(user_features, columns=categorical_features)\n",
        "\n",
        "    # Realign with features_final columns\n",
        "    user_features_aligned = user_features_encoded.reindex(columns=features_final.columns, fill_value=0)\n",
        "\n",
        "    return user_features_aligned\n",
        "\n",
        "\n",
        "\n",
        "# Get user input for the 20 features\n",
        "user_features = get_user_input()\n",
        "\n",
        "# Perform prediction\n",
        "prediction = pipeline.predict(user_features)\n",
        "\n",
        "# Print the prediction\n",
        "if prediction[0] == 0:\n",
        "    print(\"Prediction: Non-autistic\")\n",
        "else:\n",
        "    print(\"Prediction: Autistic\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iYhIF4FiUuEs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "\n",
        "# Define function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.xticks([0, 1])\n",
        "    plt.yticks([0, 1])\n",
        "\n",
        "# Reverse the confusion matrix\n",
        "conf_matrix_test_reversed = conf_matrix_test[::-1, ::-1]\n",
        "\n",
        "# Plot confusion matrix\n",
        "plot_confusion_matrix(conf_matrix_test_reversed, title='Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOs4/LvWpqQHYne1gSFyx2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}